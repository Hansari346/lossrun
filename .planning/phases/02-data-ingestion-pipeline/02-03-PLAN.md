---
phase: 02-data-ingestion-pipeline
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/lib/validation.ts
  - src/state/store.ts
autonomous: true

must_haves:
  truths:
    - "After data loading, a validation summary is available showing total rows, valid rows, skipped rows, and categorized error counts (unparsable dates, invalid amounts, missing required fields)"
    - "Every skipped row has a specific RowError explaining what field failed and what the raw value was"
    - "The validation summary is stored in a signal so the UI can reactively display it"
  artifacts:
    - path: "src/lib/validation.ts"
      provides: "validateAndParseRow() function and createEmptyValidationSummary() helper"
      exports: ["validateAndParseRow", "createEmptyValidationSummary"]
      min_lines: 60
    - path: "src/state/store.ts"
      provides: "validationSummary signal and sheetScores signal"
      contains: "validationSummary"
  key_links:
    - from: "src/lib/validation.ts"
      to: "src/lib/date-utils.ts"
      via: "import parseDate"
      pattern: "import.*parseDate.*from.*date-utils"
    - from: "src/lib/validation.ts"
      to: "src/lib/currency-utils.ts"
      via: "import parseCurrency"
      pattern: "import.*parseCurrency.*from.*currency-utils"
    - from: "src/state/store.ts"
      to: "src/types/index.ts"
      via: "import ValidationSummary, SheetScore, CompositeField"
      pattern: "import.*ValidationSummary.*from.*types"
---

<objective>
Build the validation accumulator that replaces silent row dropping with structured error reporting, and extend the signal store with validation/sheet/composite state.

Purpose: INGEST-04 (data validation with quality summary) is the bridge between parsing and user trust. Users need to see exactly what the tool understood and what it couldn't parse — not just a row count. The store extensions provide reactive state for the validation summary, sheet rankings, and composite fields that the UI will consume in plan 02-04.

Output: A validation module that parses individual rows using date-utils and currency-utils while accumulating errors, plus an extended signal store ready for the integration plan.
</objective>

<execution_context>
@~/.cursor/get-shit-done/workflows/execute-plan.md
@~/.cursor/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-data-ingestion-pipeline/02-RESEARCH.md
@src/state/store.ts
@src/types/index.ts
@src/lib/parsing.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create validation engine with row-level error accumulation</name>
  <files>src/lib/validation.ts</files>
  <action>
  Create `src/lib/validation.ts` with these exported functions:

  **`createEmptyValidationSummary(): ValidationSummary`** — Factory function returning a fresh summary with all counts at 0, empty arrays.

  **`validateAndParseRow(row: Record<string, any>, mappings: Record<string, number>, headers: string[], rowIndex: number, compositeOverrides?: Record<string, { columnIndex: number; key: string }>): { record: CanonicalRecord | null; errors: RowError[] }`**

  This function replaces the inline parsing logic currently in `applyMappingAndLoad`. For a single row:

  1. **Extract required fields using column indices from `mappings`:**
     - `site_name`: Get value at `headers[mappings.site_name]` from the row. Trim to string. If empty → push RowError for "site_name", field "Site Name", message "Missing site name".
     - `date_of_loss`: Get raw value at the mapped column. Call `parseDate(rawValue)` from date-utils. If error → push RowError with the parseDate error message. If value is null → push RowError.
     - `total_incurred`: Get raw value. Call `parseCurrency(rawValue)` from currency-utils. If error → push RowError. If value is null or not finite → push RowError.

  2. **If any required field has an error → return `{ record: null, errors }`** (row is skipped, but errors are recorded — NOT silently dropped).

  3. **Extract optional fields** using the same pattern:
     - `claim_number`: string, trimmed
     - `claim_category`: string, trimmed
     - `body_part`: string, trimmed
     - `cause_of_loss`: string, trimmed
     - `loss_description`: string, trimmed
     - `lost_days`: Call `parseCurrency(rawValue)` (it's a number parser), if error → push RowError as warning but still include the record (optional field failure doesn't skip the row)

  4. **Handle composite field overrides:** If `compositeOverrides` is provided, for each override entry (e.g., `{ cause_of_loss: { columnIndex: 5, key: "Nature of Injury" } }`), extract the composite value using the pattern: get cell value at the override column index, match against `"${key}: "` prefix, extract the value portion. Import `extractCompositeValue` from `./composite-fields` for this.

  5. **Build and return the CanonicalRecord** with all parsed values.

  **`accumulateErrors(summary: ValidationSummary, errors: RowError[]): void`** — Mutates the summary to increment error category counts:
  - For each error, increment `summary.errors` array
  - If error.field contains "date" → increment `summary.unparsableDates`
  - If error.field contains "incurred" or "amount" → increment `summary.invalidAmounts`
  - If error is for a required field that's empty → increment `summary.missingRequired`

  Imports: `ParseResult`, `RowError`, `ValidationSummary`, `CanonicalRecord` from `../types`. `parseDate` from `./date-utils`. `parseCurrency` from `./currency-utils`. `extractCompositeValue` from `./composite-fields`.

  **Critical:** The row value lookup must use COLUMN INDICES, not header name strings. The `mappings` parameter maps field keys → column indices (numbers). To get the actual cell value: `row[headers[mappings[fieldKey]]]` (get column index from mappings, get header name from headers array, use header name as row key since sheet_to_json uses headers as keys).

  **Note on row object structure:** When `sheet_to_json` is called with `header: headerArray`, the resulting objects use the header strings as keys. So to access the value at column index `i`, you look up `row[headers[i]]`.
  </action>
  <verify>
  Run `npx tsc --noEmit` — no type errors. Verify the function imports parseDate from date-utils and parseCurrency from currency-utils. Verify it returns `{ record, errors }` — never silently drops.
  </verify>
  <done>
  src/lib/validation.ts exports `validateAndParseRow`, `createEmptyValidationSummary`, and `accumulateErrors`. Every row parsing attempt produces either a valid CanonicalRecord or a list of RowErrors explaining exactly what failed. No silent drops. Composite field overrides are supported for Generic Field extraction.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extend signal store with validation, sheet ranking, and composite field signals</name>
  <files>src/state/store.ts</files>
  <action>
  Add new signals to `src/state/store.ts`:

  1. **Import new types** — add `ValidationSummary`, `SheetScore`, `CompositeField` to the existing import from `../types`.

  2. **Add new signals** after the existing signal declarations:
     ```typescript
     // === Validation state ===
     export const validationSummary = signal<ValidationSummary | null>(null);

     // === Sheet analysis state ===
     export const sheetScores = signal<SheetScore[]>([]);

     // === Composite field state ===
     export const compositeFields = signal<CompositeField[]>([]);
     ```

  3. **Add a derived signal** for quick validation status check:
     ```typescript
     export const hasValidationErrors = computed(() => {
       const vs = validationSummary.value;
       return vs !== null && vs.skippedRows > 0;
     });
     ```

  4. **Update `resetState()`** to clear the new signals:
     ```typescript
     validationSummary.value = null;
     sheetScores.value = [];
     compositeFields.value = [];
     ```

  **Do NOT change** any existing signals or their types. These are purely additive.
  </action>
  <verify>
  Run `npx tsc --noEmit` — no type errors. Verify that `validationSummary`, `sheetScores`, `compositeFields`, and `hasValidationErrors` are exported from store.ts. Verify `resetState()` clears all three new signals.
  </verify>
  <done>
  src/state/store.ts exports `validationSummary`, `sheetScores`, `compositeFields`, and `hasValidationErrors`. All are initialized to null/empty. `resetState()` clears them. Existing signals unchanged (brownfield guard).
  </done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. `src/lib/validation.ts` imports from `date-utils`, `currency-utils`, and `composite-fields`
3. `src/state/store.ts` exports `validationSummary`, `sheetScores`, `compositeFields`, `hasValidationErrors`
4. `resetState()` resets all new signals
5. `npx wrangler dev` starts without errors
</verification>

<success_criteria>
- validateAndParseRow returns `{ record: CanonicalRecord | null, errors: RowError[] }` — every outcome is explicit
- RowError contains rowIndex, field name, human-readable message, and raw value
- accumulateErrors correctly categorizes errors into unparsableDates, invalidAmounts, missingRequired
- Store has reactive signals for validationSummary, sheetScores, compositeFields
- Zero new dependencies
- Existing signals and store behavior untouched
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-ingestion-pipeline/02-03-SUMMARY.md`
</output>
